# Refactoring Smells Dataset

This project provides a dataset designed for research on refactoring test smells in JavaScript open-source projects. The dataset is intended to support studies leveraging Large Language Models (LLMs) such as GitHub Copilot and AWS CodeWhisperer.

## Overview

The dataset includes data collected from various JavaScript projects, focusing on identifying and analyzing test smells. Test smells are patterns in test code that may indicate potential maintenance issues or inefficiencies. By studying these smells, researchers aim to improve the quality and maintainability of test code.

## Objectives

- To study the effectiveness of LLMs in identifying and refactoring test smells.
- To compare the performance of tools like GitHub Copilot and AWS CodeWhisperer in addressing test smells.
- To provide insights into best practices for maintaining high-quality test code in JavaScript projects.

## Tools Used

- **GitHub Copilot**: An AI-powered code completion tool developed by GitHub.
- **AWS CodeWhisperer**: An AI coding companion provided by Amazon Web Services.

## How to Use

1. Explore the dataset to identify test smells in JavaScript projects.
2. Use LLMs like Copilot or CodeWhisperer to refactor the identified smells.
3. Analyze the results to evaluate the effectiveness of the tools.

## Contribution

Contributions to this project are welcome. If you have suggestions for improving the dataset or the research methodology, feel free to submit a pull request or open an issue.

## License

This project is licensed under [insert license here]. Please ensure compliance with the license terms when using the dataset.

---